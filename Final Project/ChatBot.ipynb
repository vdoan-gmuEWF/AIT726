{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        loader = CSVLoader(file_path=file_path, csv_args={\n",
    "            'delimiter': ',',\n",
    "            'quotechar': '\"',\n",
    "            'fieldnames': ['Name', 'Text']\n",
    "        })\n",
    "        self.RAW_KNOWLEDGE_BASE = loader.load()\n",
    "        self.MARKDOWN_SEPARATORS = [\n",
    "                                    \"\\n#{1,6} \",\n",
    "                                    \"```\\n\",\n",
    "                                    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "                                    \"\\n---+\\n\",\n",
    "                                    \"\\n___+\\n\",\n",
    "                                    \"\\n\\n\",\n",
    "                                    \"\\n\",\n",
    "                                    \" \",\n",
    "                                    \"\",\n",
    "                                    ]\n",
    "        self.EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
    "        self.KNOWLEDGE_VECTOR_DATABASE = self.create_vector_database()\n",
    "\n",
    "    def split_documents(self):\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "            AutoTokenizer.from_pretrained(self.EMBEDDING_MODEL_NAME),\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=self.MARKDOWN_SEPARATORS\n",
    "        )\n",
    "        docs_processed = []\n",
    "        current_row = None\n",
    "        chunk_index = 0\n",
    "\n",
    "        for document in self.RAW_KNOWLEDGE_BASE:\n",
    "            if document.metadata['row'] != current_row:\n",
    "                current_row = document.metadata['row']\n",
    "                chunk_index = 1\n",
    "            else:\n",
    "                chunk_index += 1\n",
    "            document.metadata[\"id\"] = f\"{document.metadata.get('source', 'unknown')} :{document.metadata['row']}:{chunk_index}\"\n",
    "            docs_processed += text_splitter.split_documents([document])\n",
    "            \n",
    "        unique_texts = {}\n",
    "        docs_processed_unique = []\n",
    "        for doc in docs_processed:\n",
    "            if doc.page_content not in unique_texts:\n",
    "                unique_texts[doc.page_content] = True\n",
    "                docs_processed_unique.append(doc)\n",
    "\n",
    "        return docs_processed_unique\n",
    "            \n",
    "    \n",
    "    def transform(self):\n",
    "        print(f\"Model's maximum sequence length: {SentenceTransformer('thenlper/gte-small').max_seq_length}\")\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.EMBEDDING_MODEL_NAME)\n",
    "        lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(self.split_documents())]\n",
    "\n",
    "        # Plot the distribution of document lengths, counted as the number of tokens\n",
    "        fig = pd.Series(lengths).hist()\n",
    "        plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "        plt.show()\n",
    "        \n",
    "    def get_embedding_model(self):\n",
    "        try:\n",
    "            return HuggingFaceEmbeddings(\n",
    "                                            model_name=self.EMBEDDING_MODEL_NAME,\n",
    "                                            multi_process=True,\n",
    "                                            encode_kwargs={\"normalize_embeddings\": True}\n",
    "                                        )\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating embeddings: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def create_vector_database(self):\n",
    "        return FAISS.from_documents(self.split_documents(), self.get_embedding_model(), distance_strategy=DistanceStrategy.COSINE)\n",
    "    \n",
    "    def project_2d_embedding(self, user_query):\n",
    "        embedding_model = self.get_embedding_model()\n",
    "        query_vector = embedding_model.embed_query(user_query)\n",
    "        docs_processed = self.split_documents()\n",
    "        embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "        embeddings_2d = [\n",
    "            list(self.KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "        ] + [query_vector]\n",
    "        documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(\n",
    "            [\n",
    "                {\n",
    "                    \"x\": documents_projected[i, 0],\n",
    "                    \"y\": documents_projected[i, 1],\n",
    "                    \"source\": docs_processed[i].metadata[\"source\"].split(\"/\")[1],\n",
    "                    \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "                    \"symbol\": \"circle\",\n",
    "                    \"size_col\": 4,\n",
    "                }\n",
    "                for i in range(len(docs_processed))\n",
    "            ]\n",
    "            + [\n",
    "                {\n",
    "                    \"x\": documents_projected[-1, 0],\n",
    "                    \"y\": documents_projected[-1, 1],\n",
    "                    \"source\": \"User query\",\n",
    "                    \"extract\": user_query,\n",
    "                    \"size_col\": 100,\n",
    "                    \"symbol\": \"star\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Visualize the embedding\n",
    "        fig = px.scatter(\n",
    "            df,\n",
    "            x=\"x\",\n",
    "            y=\"y\",\n",
    "            color=\"source\",\n",
    "            hover_data=\"extract\",\n",
    "            size=\"size_col\",\n",
    "            symbol=\"symbol\",\n",
    "            color_discrete_map={\"User query\": \"black\"},\n",
    "            width=1000,\n",
    "            height=700,\n",
    "        )\n",
    "        fig.update_traces(\n",
    "            marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "            selector=dict(mode=\"markers\"),\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            legend_title_text=\"<b>Chunk source</b>\",\n",
    "            title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    "        )\n",
    "        fig.show()\n",
    "            \n",
    "    def retrive(self, user_query):\n",
    "        return self.KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReaderLLM:\n",
    "    def __init__(self):\n",
    "        PROMPT_TEMPLATE = \"\"\"\n",
    "                            Answer the question based only on the following context:\n",
    "\n",
    "                            {context}\n",
    "\n",
    "                            ---\n",
    "\n",
    "                            Answer the question based on the above context: {question}\n",
    "                            \"\"\"\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "        self.llmModel = Ollama(model=\"llama3.1\")\n",
    "\n",
    "    def query_rag(self, ragModel, query_text: str ):\n",
    "        results = ragModel.retrive(query_text)\n",
    "        context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in results])\n",
    "        prompt = self.prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "        response_text = self.llmModel.invoke(prompt)\n",
    "        \n",
    "        sources = {doc.metadata.get(\"id\", None) for doc in results}\n",
    "        formatted_response = f\"\\nResponse:\\n{response_text}\\n\\nSources: {sources}\\n---\"\n",
    "        \n",
    "        print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        self.ragModel = Retriever(file_path='./data/bridge.csv')\n",
    "        self.reader_llm = ReaderLLM()\n",
    "        \n",
    "    def answer(self, question: str):\n",
    "        print(f\"Question:\\n{question}\")\n",
    "        self.reader_llm.query_rag(self.ragModel, question)\n",
    "\n",
    "    def ask(self):\n",
    "        while True:\n",
    "            question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
    "            if question.lower() == 'exit': \n",
    "                break\n",
    "            self.answer(question)\n",
    "    \n",
    "    def launch(self):\n",
    "        self.ask()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Why is Acoustic Emission (AE) not effective in detecting arrested cracks or damage that is not progressing under load application?\n",
      "\n",
      "Response:\n",
      "Acoustic Emission (AE) is not effective in detecting arrested cracks or damage that is not progressing under load application because if a fatigue crack is not increasing in length, AE signals generally are not produced.\n",
      "\n",
      "Sources: {'./data/bridge.csv :1:1'}\n",
      "---\n",
      "Question:\n",
      "How does AE technology help in monitoring crack growth and assessing the effectiveness of retrofits in steel bridges?\n",
      "\n",
      "Response:\n",
      "According to the context, AE technology helps in monitoring crack growth and assessing the effectiveness of retrofits in steel bridges by:\n",
      "\n",
      "* Detecting acoustic signals produced from cracks and other defects as they grow under load application\n",
      "* Analyzing these signals to determine the rate at which damage is progressing\n",
      "* Locating the source of the damage using triangulation based on the arrival time of acoustic waves and wave velocity in the material\n",
      "* Monitoring crack growth over time, such as during traffic loads on highway bridges\n",
      "* Assessing whether a retrofit intended to arrest cracking has been successful by monitoring AE signals and determining if they have decreased or stopped\n",
      "\n",
      "In essence, AE technology provides real-time feedback on the effectiveness of retrofits and helps engineers monitor the health of steel bridges more accurately.\n",
      "\n",
      "Sources: {'./data/bridge.csv :1:1'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "ChatBot().launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
